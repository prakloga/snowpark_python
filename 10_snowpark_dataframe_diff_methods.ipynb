{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import cachetools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import configparser\n",
    "from snowflake.snowpark import Session\n",
    "from copy import copy\n",
    "from snowflake.snowpark import Row\n",
    "import snowflake.snowpark.functions as F\n",
    "from snowflake.snowpark.functions import col, lit, sql_expr, get, get_path, udf, udtf, table_function, sproc, seq8, uniform, when_matched, when_not_matched, cast, try_cast, asc, asc_nulls_first, asc_nulls_last, collate, startswith, endswith, equal_nan, is_null, in_, when\n",
    "from snowflake.snowpark.types import StructType, StructField, StringType, IntegerType, DecimalType, LongType, BooleanType, FloatType, PandasSeries, PandasSeriesType, PandasDataFrame, PandasDataFrameType\n",
    "from snowflake.snowpark.exceptions import SnowparkJoinException, SnowparkSQLException\n",
    "from snowflake.snowpark.files import SnowflakeFile\n",
    "from snowflake.snowpark.column import METADATA_FILENAME, METADATA_FILE_ROW_NUMBER\n",
    "from collections import Counter\n",
    "from typing import Iterable, Tuple\n",
    "\n",
    "# Read snowflake credentials securely\n",
    "config = configparser.ConfigParser()\n",
    "config.read('assets/credentials.cfg')\n",
    "\n",
    "connection_parameters = dict(\n",
    "   account   =  config['SNOWPARKAWS']['SNOWFLAKE_ACCOUNT'],\n",
    "   user      =  config['SNOWPARKAWS']['SNOWFLAKE_USER'],\n",
    "   password  =  config['SNOWPARKAWS']['SNOWFLAKE_PASSWORD'],\n",
    "   role      =  config['SNOWPARKAWS']['SNOWFLAKE_ROLE'],  # optional\n",
    "   warehouse =  config['SNOWPARKAWS']['SNOWFLAKE_WAREHOUSE'],  # optional\n",
    "   database  =  config['SNOWPARKAWS']['SNOWFLAKE_DATABASE'],  # optional\n",
    "   schema    =  config['SNOWPARKAWS']['SNOWFLAKE_SCHEMA'],  # optional\n",
    ")\n",
    "\n",
    "# Pass this dictionary to the Session.builder.configs method to return a builder object that has these connection parameters.\n",
    "# Call the create method of the builder to establish the session.\n",
    "session = Session.builder.configs(connection_parameters).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Getting Started with Snowflake Snowpark Dataframes`\n",
    "\n",
    "snowflake.snowpark.DataFrame represents a lazily-evaluated relational dataset that contains a collection of Row objects with columns defined by a schema (column name and type).\n",
    "\n",
    "- A DataFrame is considered lazy because it encapsulates the computation or query required to produce a relational dataset\n",
    "- The computation is not performed until you call a method that performs an action \n",
    "\n",
    "There are multiple ways to create a dataframe using snowpark\n",
    "\n",
    "1. Using `session.create_dataframe` to create a dataframe\n",
    "1. Using `session.table()` to create a dataframe\n",
    "1. Using `session.sql()` to create a dataframe\n",
    "1. Using `session.read.csv/json/etc..,` property of DataFrameReader to create a dataframe\n",
    "1. Creating `new dataframe` by applying `transformation` on existing dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PutResult(source='csv_dataset.csv', target='csv_dataset.csv', source_size=153, target_size=160, source_compression='NONE', target_compression='NONE', status='UPLOADED', message='')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snowflake.snowpark.types import StructField,StructType,StringType,IntegerType\n",
    "\n",
    "# Import local file into Snowflake named internal stage\n",
    "session.file.put(local_file_name='datasets/csv_dataset.csv',stage_location='@SF_INT_STG',auto_compress=False ,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "|\"COL1\"     |\n",
      "-------------\n",
      "|Snowflake  |\n",
      "|Snowpark   |\n",
      "-------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create new dataframe\n",
    "df = session.create_dataframe([\"Snowflake\",\"Snowpark\"], schema=[\"col1\"])\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>START_TIME</th>\n",
       "      <th>END_TIME</th>\n",
       "      <th>WAREHOUSE_ID</th>\n",
       "      <th>WAREHOUSE_NAME</th>\n",
       "      <th>CREDITS_USED</th>\n",
       "      <th>CREDITS_USED_COMPUTE</th>\n",
       "      <th>CREDITS_USED_CLOUD_SERVICES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-16 09:00:00-08:00</td>\n",
       "      <td>2023-12-16 10:00:00-08:00</td>\n",
       "      <td>40</td>\n",
       "      <td>SNOWPARK_WH</td>\n",
       "      <td>0.244249</td>\n",
       "      <td>0.242778</td>\n",
       "      <td>0.001471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-27 07:00:00-08:00</td>\n",
       "      <td>2023-11-27 08:00:00-08:00</td>\n",
       "      <td>5</td>\n",
       "      <td>TASTY_DS_WH</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-12 19:00:00-08:00</td>\n",
       "      <td>2023-12-12 20:00:00-08:00</td>\n",
       "      <td>43</td>\n",
       "      <td>HOL_WH</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-12-14 06:00:00-08:00</td>\n",
       "      <td>2023-12-14 07:00:00-08:00</td>\n",
       "      <td>0</td>\n",
       "      <td>CLOUD_SERVICES_ONLY</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-12-11 15:00:00-08:00</td>\n",
       "      <td>2023-12-11 16:00:00-08:00</td>\n",
       "      <td>31</td>\n",
       "      <td>SNOWPARK_OPT_WH</td>\n",
       "      <td>0.432140</td>\n",
       "      <td>0.431667</td>\n",
       "      <td>0.000474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-11-30 13:00:00-08:00</td>\n",
       "      <td>2023-11-30 14:00:00-08:00</td>\n",
       "      <td>1</td>\n",
       "      <td>COMPUTE_WH</td>\n",
       "      <td>0.076943</td>\n",
       "      <td>0.076389</td>\n",
       "      <td>0.000554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-12-04 12:00:00-08:00</td>\n",
       "      <td>2023-12-04 13:00:00-08:00</td>\n",
       "      <td>1</td>\n",
       "      <td>COMPUTE_WH</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-11-27 07:00:00-08:00</td>\n",
       "      <td>2023-11-27 08:00:00-08:00</td>\n",
       "      <td>10</td>\n",
       "      <td>TASTY_BI_WH</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-12-12 06:00:00-08:00</td>\n",
       "      <td>2023-12-12 07:00:00-08:00</td>\n",
       "      <td>0</td>\n",
       "      <td>CLOUD_SERVICES_ONLY</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-11-27 17:00:00-08:00</td>\n",
       "      <td>2023-11-27 18:00:00-08:00</td>\n",
       "      <td>0</td>\n",
       "      <td>CLOUD_SERVICES_ONLY</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 START_TIME                  END_TIME  WAREHOUSE_ID  \\\n",
       "0 2023-12-16 09:00:00-08:00 2023-12-16 10:00:00-08:00            40   \n",
       "1 2023-11-27 07:00:00-08:00 2023-11-27 08:00:00-08:00             5   \n",
       "2 2023-12-12 19:00:00-08:00 2023-12-12 20:00:00-08:00            43   \n",
       "3 2023-12-14 06:00:00-08:00 2023-12-14 07:00:00-08:00             0   \n",
       "4 2023-12-11 15:00:00-08:00 2023-12-11 16:00:00-08:00            31   \n",
       "5 2023-11-30 13:00:00-08:00 2023-11-30 14:00:00-08:00             1   \n",
       "6 2023-12-04 12:00:00-08:00 2023-12-04 13:00:00-08:00             1   \n",
       "7 2023-11-27 07:00:00-08:00 2023-11-27 08:00:00-08:00            10   \n",
       "8 2023-12-12 06:00:00-08:00 2023-12-12 07:00:00-08:00             0   \n",
       "9 2023-11-27 17:00:00-08:00 2023-11-27 18:00:00-08:00             0   \n",
       "\n",
       "        WAREHOUSE_NAME  CREDITS_USED  CREDITS_USED_COMPUTE  \\\n",
       "0          SNOWPARK_WH      0.244249              0.242778   \n",
       "1          TASTY_DS_WH      0.000041              0.000000   \n",
       "2               HOL_WH      0.000125              0.000000   \n",
       "3  CLOUD_SERVICES_ONLY      0.000006              0.000000   \n",
       "4      SNOWPARK_OPT_WH      0.432140              0.431667   \n",
       "5           COMPUTE_WH      0.076943              0.076389   \n",
       "6           COMPUTE_WH      0.000091              0.000000   \n",
       "7          TASTY_BI_WH      0.000065              0.000000   \n",
       "8  CLOUD_SERVICES_ONLY      0.000011              0.000000   \n",
       "9  CLOUD_SERVICES_ONLY      0.000028              0.000000   \n",
       "\n",
       "   CREDITS_USED_CLOUD_SERVICES  \n",
       "0                     0.001471  \n",
       "1                     0.000041  \n",
       "2                     0.000125  \n",
       "3                     0.000006  \n",
       "4                     0.000474  \n",
       "5                     0.000554  \n",
       "6                     0.000091  \n",
       "7                     0.000065  \n",
       "8                     0.000011  \n",
       "9                     0.000028  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Dataframe using session.table\n",
    "df_via_table = session.table('SNOWFLAKE.ACCOUNT_USAGE.WAREHOUSE_METERING_HISTORY')\n",
    "df_via_table.limit(10).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>START_TIME</th>\n",
       "      <th>END_TIME</th>\n",
       "      <th>WAREHOUSE_NAME</th>\n",
       "      <th>CREDITS_USED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-13 08:00:00-08:00</td>\n",
       "      <td>2023-12-13 09:00:00-08:00</td>\n",
       "      <td>SNOWPARK_OPT_WH</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-27 18:00:00-08:00</td>\n",
       "      <td>2023-11-27 19:00:00-08:00</td>\n",
       "      <td>SNOWPARK_OPT_WH</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-18 08:00:00-08:00</td>\n",
       "      <td>2023-12-18 09:00:00-08:00</td>\n",
       "      <td>COMPUTE_WH</td>\n",
       "      <td>0.037500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-30 07:00:00-08:00</td>\n",
       "      <td>2023-11-30 08:00:00-08:00</td>\n",
       "      <td>COMPUTE_WH</td>\n",
       "      <td>0.043889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-28 09:00:00-08:00</td>\n",
       "      <td>2023-11-28 10:00:00-08:00</td>\n",
       "      <td>CLOUD_SERVICES_ONLY</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-12-18 06:00:00-08:00</td>\n",
       "      <td>2023-12-18 07:00:00-08:00</td>\n",
       "      <td>COMPUTE_WH</td>\n",
       "      <td>0.017222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-12-18 06:00:00-08:00</td>\n",
       "      <td>2023-12-18 07:00:00-08:00</td>\n",
       "      <td>CLOUD_SERVICES_ONLY</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-12-14 13:00:00-08:00</td>\n",
       "      <td>2023-12-14 14:00:00-08:00</td>\n",
       "      <td>SNOWPARK_WH</td>\n",
       "      <td>0.101283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-12-11 11:00:00-08:00</td>\n",
       "      <td>2023-12-11 12:00:00-08:00</td>\n",
       "      <td>COMPUTE_WH</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-12-13 08:00:00-08:00</td>\n",
       "      <td>2023-12-13 09:00:00-08:00</td>\n",
       "      <td>COMPUTE_WH</td>\n",
       "      <td>0.017778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 START_TIME                  END_TIME       WAREHOUSE_NAME  \\\n",
       "0 2023-12-13 08:00:00-08:00 2023-12-13 09:00:00-08:00      SNOWPARK_OPT_WH   \n",
       "1 2023-11-27 18:00:00-08:00 2023-11-27 19:00:00-08:00      SNOWPARK_OPT_WH   \n",
       "2 2023-12-18 08:00:00-08:00 2023-12-18 09:00:00-08:00           COMPUTE_WH   \n",
       "3 2023-11-30 07:00:00-08:00 2023-11-30 08:00:00-08:00           COMPUTE_WH   \n",
       "4 2023-11-28 09:00:00-08:00 2023-11-28 10:00:00-08:00  CLOUD_SERVICES_ONLY   \n",
       "5 2023-12-18 06:00:00-08:00 2023-12-18 07:00:00-08:00           COMPUTE_WH   \n",
       "6 2023-12-18 06:00:00-08:00 2023-12-18 07:00:00-08:00  CLOUD_SERVICES_ONLY   \n",
       "7 2023-12-14 13:00:00-08:00 2023-12-14 14:00:00-08:00          SNOWPARK_WH   \n",
       "8 2023-12-11 11:00:00-08:00 2023-12-11 12:00:00-08:00           COMPUTE_WH   \n",
       "9 2023-12-13 08:00:00-08:00 2023-12-13 09:00:00-08:00           COMPUTE_WH   \n",
       "\n",
       "   CREDITS_USED  \n",
       "0      0.000009  \n",
       "1      0.000050  \n",
       "2      0.037500  \n",
       "3      0.043889  \n",
       "4      0.000018  \n",
       "5      0.017222  \n",
       "6      0.000014  \n",
       "7      0.101283  \n",
       "8      0.000016  \n",
       "9      0.017778  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Dataframe using session.sql\n",
    "df_via_sql = session.sql('SELECT START_TIME, END_TIME, WAREHOUSE_NAME, CREDITS_USED FROM SNOWFLAKE.ACCOUNT_USAGE.WAREHOUSE_METERING_HISTORY')\n",
    "df_via_sql.limit(10).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "|\"Email No.\"  |\"THE\"  |\"TO\"  |\n",
      "------------------------------\n",
      "|Email 1      |0      |11    |\n",
      "|Email 2      |8      |3     |\n",
      "|Email 3      |0      |3     |\n",
      "|Email 4      |0      |5     |\n",
      "|Email 5      |7      |12    |\n",
      "|Email 6      |4      |44    |\n",
      "|Email 7      |5      |9     |\n",
      "|Email 8      |0      |33    |\n",
      "|Email 9      |2      |5     |\n",
      "|Email 10     |4      |1     |\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating Dataframe using session.read property\n",
    "csv_schema = StructType([StructField('Email No.', StringType())\n",
    "                        , StructField(\"the\", IntegerType())\n",
    "                        , StructField(\"to\", IntegerType())])\n",
    "\n",
    "df_csv_file = session.read.options({\"field_delimiter\":\",\", \"skip_header\":1, \"pattern\":\".*[.]csv\"}).schema(csv_schema).csv(\"@SF_INT_STG/csv_dataset.csv\")\n",
    "df_csv_file.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Types of Operations on a Dataframe` \n",
    "\n",
    "The operations on DataFrame can be divided into two types:\n",
    "\n",
    "- **Transformations** produce a new DataFrame from one or more existing DataFrames. Note that transformations are lazy and don’t cause the DataFrame to be evaluated.\n",
    "\n",
    "- **Actions** cause the DataFrame to be evaluated. When you call a method that performs an action, Snowpark sends the SQL query for the DataFrame to the server for evaluation.\n",
    "\n",
    "Follow the Snowpark for Python Documentation to understand various use cases on Transformation and performing actions on the DataFrame - [Snowflake.Snowpark.DataFrame](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/api/snowflake.snowpark.DataFrame)\n",
    "\n",
    "---\n",
    "\n",
    "Complete List of All DataFrame Methods - [Here](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/api/snowflake.snowpark.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "|\"NAME\"   |\"AGE\"  |\"SALARY\"  |\n",
      "------------------------------\n",
      "|person1  |25     |1000.0    |\n",
      "|person2  |30     |2000.0    |\n",
      "|person2  |25     |2300.0    |\n",
      "|person3  |40     |5000.0    |\n",
      "|person3  |25     |5400.0    |\n",
      "|person3  |30     |NULL      |\n",
      "|NULL     |NULL   |6000.0    |\n",
      "|NULL     |NULL   |nan       |\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from snowflake.snowpark.types import StructType, StructField, IntegerType,StringType,FloatType\n",
    "\n",
    "schema = StructType([StructField('name',StringType()),\n",
    "                     StructField('age',IntegerType()),\n",
    "                     StructField('salary',FloatType())\n",
    "                     ])\n",
    "\n",
    "dataset=[[\"person1\",25,1000.00]\n",
    "        ,[\"person2\",30,2000.00]\n",
    "        ,[\"person2\",25,2300.00]\n",
    "        ,[\"person3\",40,5000.00]\n",
    "        ,[\"person3\",25,5400.00]\n",
    "        ,[\"person3\",30,None]\n",
    "        ,[None,None,6000.00]\n",
    "        ,[None,None,float('nan')]\n",
    "         ]\n",
    "\n",
    "df = session.create_dataframe(data=dataset, schema=schema)\n",
    "df.schema.names\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "|\"AGE\"  |\"COL1\"  |\"COL2\"  |\n",
      "---------------------------\n",
      "|25     |5400.0  |2300.0  |\n",
      "|NULL   |nan     |nan     |\n",
      "|30     |2000.0  |2000.0  |\n",
      "|40     |5000.0  |5000.0  |\n",
      "---------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aggregate Functions on DataFrame using dataFrame.agg()\n",
    "from snowflake.snowpark.functions import col, stddev, stddev_pop, min, max, median\n",
    "\n",
    "(df.group_by(col(\"AGE\"))\n",
    "   .agg(max(col(\"SALARY\")).as_(\"col1\")\n",
    "       ,median(col(\"SALARY\")).as_(\"col2\"))\n",
    "  .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [DataFrame.cache_result](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/api/snowflake.snowpark.DataFrame.cache_result)\n",
    "\n",
    "  - Caches the content of this DataFrame to create a new cached Table DataFrame.\n",
    "\n",
    "  - All subsequent operations on the returned cached DataFrame are performed on the cached data and have no effect on the original DataFrame.\n",
    "\n",
    "  - You can use `Table.drop_table()` or the `with` statement to clean up the cached result when it’s not needed. Refer to the example code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_result = session.sql(\"create temp table result(num int)\").collect()\n",
    "insert_result = session.sql(\"insert into result values(1),(2)\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "|\"NUM\"  |\n",
      "---------\n",
      "|1      |\n",
      "|2      |\n",
      "---------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = session.table(\"result\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "|\"NUM\"  |\n",
      "---------\n",
      "|1      |\n",
      "|2      |\n",
      "---------\n",
      "\n",
      "---------\n",
      "|\"NUM\"  |\n",
      "---------\n",
      "|1      |\n",
      "|2      |\n",
      "|3      |\n",
      "---------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run cache_result and then insert into the original table to see that the cached result is not affected\n",
    "df1 = df.cache_result()\n",
    "\n",
    "# Insert new record\n",
    "insert_result = session.sql(\"insert into result values(3)\").collect()\n",
    "\n",
    "# cached dataframe result\n",
    "df1.show()\n",
    "\n",
    "# original dataframe result\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "|\"NUM\"  |\n",
      "---------\n",
      "|1      |\n",
      "|2      |\n",
      "---------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can run cache_result on a result that has already been cached\n",
    "df2 = df1.cache_result()\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop RESULT and see that the cached results still exist\n",
    "_ = session.sql(f\"drop table result\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "|\"NUM\"  |\n",
      "---------\n",
      "|1      |\n",
      "|2      |\n",
      "---------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "|\"NUM\"  |\n",
      "---------\n",
      "|1      |\n",
      "|2      |\n",
      "---------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the cached result\n",
    "df2.drop_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "|\"NUM\"  |\n",
      "---------\n",
      "|1      |\n",
      "|2      |\n",
      "---------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use context manager to clean up the cached result after it's use.\n",
    "with df1.cache_result() as df3:\n",
    "    df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close Snowpark session\n",
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowpark10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
